SEED: 3407            # random seed
No_Bar: False        # Turn off the progressive bar

use_MPE: True
rel_pos_num: 128
str_size: 256
min_sigma: 3.0
max_sigma: 3.75
round: 64
rezero_for_mpe: True

SFE_structure: resnet # or transformer

# model_name: '0522_ZITS_video_firstTry'
transformer_ckpt_path: './ckpt/0521_ZITS_video_YouTubeVOS_08hole_02valid_1edge_1line_minMaxNorm_oldEdge_bs2_bce/best.pth'
# gen_weights_path0: './ckpt/lama_youtube/InpaintingModel_video_gen.pth'   # Not required at the time of eval
# dis_weights_path0: './ckpt/lama_youtube/InpaintingModel_video_dis.pth'   # Not required at the time of eval
structure_upsample_path: './ckpt/StructureUpsampling.pth'
###########################
# modify the line path
# train_line_path: "./places2_train_wireframes"
# eval_line_path: "./places2_val_wireframes"
# modify the image path
# TRAIN_FLIST: /home/wmlce/places365_standard/places2_all/train_list.txt
# VAL_FLIST: /home/wmlce/places365_standard/places2_all/test_sub_list.txt
# TEST_FLIST: /home/wmlce/places365_standard/places2_all/test_sub_list.txt
# set the GT images folder for metrics computation
# GT_Val_FOLDER: '/home/wmlce/places365_standard/val_512img_for_eval'
# modify the mask path
# TRAIN_MASK_FLIST: [ '/home/wmlce/irregular_mask/irregular_mask_list.txt',
#                     '/home/wmlce/coco_mask/coco_mask_list.txt' ]
# MASK_RATE: [0.4, 0.8, 1.0]
# TEST_MASK_FLIST: /home/wmlce/Image-Transformer-Inpainting/data/indoor/test_mask

# BATCH_SIZE: 18                 # input batch size for training
BATCH_SIZE: 2                 # input batch size for training
# INPUT_SIZE: 512               # input image size for training 0 for original size
INPUT_SIZE: 256               # input image size for training 0 for original size
START_ITERS: 800000             # start iters for lama
# MIX_ITERS: 808000                # gradually mix the edge and line with prediction from transformer
# MIX_ITERS: 600000                # gradually mix the edge and line with prediction from transformer
MIX_ITERS: 91600                # gradually mix the edge and line with prediction from transformer
Turning_Point: 94000            # only use the predict from transformer for edge and line
# MAX_ITERS: 850001                # maximum number of iterations to train the model
MAX_ITERS: 100000                # maximum number of iterations to train the model

SAVE_INTERVAL: 1000           # how many iterations to wait before saving model (0: never)
# SAMPLE_INTERVAL: 1000         # how many iterations to wait before sampling (0: never)
SAMPLE_INTERVAL: 2000         # how many iterations to wait before sampling (0: never)
SAMPLE_SIZE: 6               # number of images to sample
# EVAL_INTERVAL: 5000              # how many iterations to wait before model evaluation (0: never)
EVAL_INTERVAL: 2000              # how many iterations to wait before model evaluation (0: never)
LOG_INTERVAL: 500            # how many iterations to wait before logging training status (0: never)

run_title: ''

training_model:
  kind: default
  net: ZITS_video
  no_dis: 0
losses:
  l1:
    weight_missing: 0
    weight_known: 10
  perceptual:
    weight: 0
  adversarial:
    weight: 10
    gp_coef: 0.001
    mask_as_fake_target: true
    allow_scale_mask: true
  feature_matching:
    weight: 100
  resnet_pl:
    weight: 30
    weights_path: './ckpt'   # path to ade20k pretrained perceptual loss model provided by LaMa
  GAN_LOSS: hinge
  hole_weight: 1
  valid_weight: 1
optimizers:
  warmup_steps: 2000
  generator:
    kind: adam
    lr: 3.0e-4
  discriminator:
    kind: adam
    lr: 1.0e-4
  decay_steps: 40000
  decay_rate: 0.5

generator:
  input_nc: 4
  output_nc: 3
  ngf: 64
  n_downsampling: 3
  n_blocks: 9
  add_out_act: sigmoid
  init_conv_kwargs:
    ratio_gin: 0
    ratio_gout: 0
    enable_lfu: false
  downsample_conv_kwargs:
    ratio_gin: 0
    ratio_gout: 0
    enable_lfu: false
  resnet_conv_kwargs:
    ratio_gin: 0.75
    ratio_gout: 0.75
    enable_lfu: false
discriminator:
  input_nc: 3


ref_frame_num: 5
